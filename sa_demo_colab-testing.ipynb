{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# spellcheck"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sensitivity Analysis Made Easy with the EMA Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Google Colab version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the main notebook of the workshop on *sensitivity analysis* (SA) at the Social Simulation Festival 2021. Here we will demonstrate how to do Variance-based SA also know as [Sobol SA](https://en.wikipedia.org/wiki/Variance-based_sensitivity_analysis) on a relatively simple model [virus on network](https://ccl.northwestern.edu/netlogo/models/VirusonaNetwork). The idea is that you reuse (read copy-paste) this code your own model. Therefore, we tried to keep simple and avoid extensive side steps from.\n",
    "\n",
    "This notebook is tuned to be run on [Google Colab](https://colab.research.google.com/) and has a couple of extra lines of code. If you want to use it on your local machine please use `sa_demo_local_machine.ipynb`.\n",
    "\n",
    "The core packages used in this notebook are [Mesa](https://mesa.readthedocs.io/en/stable/) to define an ABM model in Python, [EMA Workbench](https://emaworkbench.readthedocs.io/en/latest/) to design and run experiments, [SALib](https://salib.readthedocs.io/en/latest/) to conduct SA (within EMA Workbench). Also, we used one pretty plotting function of [pyNetLogo](https://pynetlogo.readthedocs.io/en/latest/).\n",
    "\n",
    "The notebook follows a simplified SA workflow and has 5 sections-steps:\n",
    "\n",
    "0. Install and import all necessary packages,\n",
    "1. Load and parametrize the model,\n",
    "2. Design and run experiments,\n",
    "3. Do SA,\n",
    "4. Visualize SA outcomes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Installations and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repo to make its file available for Google Colab\n",
    "!git clone https://github.com/BROSE-Uninc/SSF2021.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "!pip install ema_workbench mesa ipyparallel SALib &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kleinraphael/opt/anaconda3/lib/python3.8/site-packages/ema_workbench/em_framework/optimization.py:48: ImportWarning: platypus based optimization not available\n",
      "  warnings.warn(\"platypus based optimization not available\", ImportWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "\n",
    "# Import EMA Workbench modules\n",
    "from ema_workbench import ReplicatorModel, RealParameter, BooleanParameter, IntegerParameter, Constant, TimeSeriesOutcome, perform_experiments, save_results, ema_logging\n",
    "\n",
    "# Initialize logger to keep track of experiments run\n",
    "ema_logging.log_to_stderr(ema_logging.INFO)\n",
    "\n",
    "# Import Mesa virus on network model\n",
    "from SSF2021.src import model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load & parametrize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# explain what is about to happen here more extensively\n",
    "# shortly explain the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The very first step of SA with EMA Workbench is to define or \"load\" the model as a function. That is, EMA Workbench treats all models as functions (read black boxes). They suppose to have **inputs** (parameters, constants, uncertainties and policy levers) and **outputs** (outcomes, KPIs). The model structure is not interesting for EMA Workbench. It may be something simple as `def func(x)` which just returns x + 1. \n",
    "\n",
    "One important feature of our model is that it has *time* component.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting up the virus on network model simulation as a function\n",
    "def model_virus_on_network(num_nodes=1, \n",
    "                           avg_node_degree=1, \n",
    "                           initial_outbreak_size=1, \n",
    "                           virus_spread_chance=1, \n",
    "                           virus_check_frequency=1, \n",
    "                           recovery_chance=1, \n",
    "                           gain_resistance_chance=1,\n",
    "                           steps=10):\n",
    "    \n",
    "    from src import model\n",
    "    \n",
    "    # Initialising the model\n",
    "    virus_on_network = model.VirusOnNetwork(num_nodes=num_nodes, \n",
    "                                            avg_node_degree=avg_node_degree, \n",
    "                                            initial_outbreak_size=initial_outbreak_size, \n",
    "                                            virus_spread_chance=virus_spread_chance, \n",
    "                                            virus_check_frequency=virus_check_frequency, \n",
    "                                            recovery_chance=recovery_chance, \n",
    "                                            gain_resistance_chance=gain_resistance_chance)\n",
    "                \n",
    "    # Run the model steps times\n",
    "    virus_on_network.run_model(steps)\n",
    "    \n",
    "    # Get model outcomes\n",
    "    outcomes = virus_on_network.datacollector.get_model_vars_dataframe()\n",
    "    \n",
    "    # Return model outcomes\n",
    "    return {'TIME' : list(range(steps + 1)),\n",
    "            \"Infected\" : outcomes[\"Infected\"].tolist(),\n",
    "            \"Susceptible\" : outcomes[\"Susceptible\"].tolist(),\n",
    "            \"Resistant\" : outcomes[\"Resistant\"].tolist()}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's parametrize and test out our Mesa model. What suppose to happen? First, no errors :-) Second, after we run function `model_virus_on_network` it has to give us a set of model outcomes. Let's try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TIME': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       " 'Infected': [1, 5, 9, 14, 14, 16, 17, 19, 19, 18, 25],\n",
       " 'Susceptible': [29, 25, 20, 15, 15, 13, 12, 10, 9, 10, 3],\n",
       " 'Resistant': [0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2]}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parametrize the model\n",
    "num_nodes = 30\n",
    "avg_node_degree = 3\n",
    "initial_outbreak_size = 1\n",
    "virus_spread_chance = 0.4\n",
    "virus_check_frequency = 0.2\n",
    "recovery_chance = 0.4\n",
    "gain_resistance_chance = 0.3\n",
    "steps = 10\n",
    "\n",
    "model_virus_on_network(num_nodes=num_nodes, \n",
    "                       avg_node_degree=avg_node_degree, \n",
    "                       initial_outbreak_size=initial_outbreak_size, \n",
    "                       virus_spread_chance=virus_spread_chance, \n",
    "                       virus_check_frequency=virus_check_frequency, \n",
    "                       recovery_chance=recovery_chance, \n",
    "                       gain_resistance_chance=gain_resistance_chance,\n",
    "                       steps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Design EMA experiments\n",
    "\n",
    "In this part, we define the experiments. First, we initialise the workbench, then we define the parameters that need to change from experiment to experiment, we define the constant parameters (number of steps and initial outbreak) and finally we define the output parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the model into the EMA workbench\n",
    "model = ReplicatorModel('virusnetwork', function=model_virus_on_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining ranges for the parameters to be varied\n",
    "# model.uncertainties = [IntegerParameter(\"num_nodes\", 10, 100),\n",
    "#                        IntegerParameter(\"avg_node_degree\", 2, 8),\n",
    "#                        RealParameter(\"virus_spread_chance\", 0.1, 1),\n",
    "#                        RealParameter(\"virus_check_frequency\", 0.1, 1),\n",
    "#                        RealParameter(\"recovery_chance\", 0.1, 1),\n",
    "#                        RealParameter(\"gain_resistance_chance\", 0.1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # defining ranges for the parameters to be varied\n",
    "model.uncertainties = [RealParameter(\"virus_check_frequency\", 0.1, 1),\n",
    "                       RealParameter(\"recovery_chance\", 0.1, 1),\n",
    "                       RealParameter(\"gain_resistance_chance\", 0.1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the parameters that will remain constant\n",
    "model.constants = [Constant(\"initial_outbreak_size\", 1),\n",
    "                   Constant('steps', 30),\n",
    "                   Constant(\"num_nodes\", 30),\n",
    "                   Constant(\"avg_node_degree\", 3),\n",
    "                   Constant(\"virus_spread_chance\", 0.2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the outputs of interests from the model\n",
    "model.outcomes = [TimeSeriesOutcome('TIME'),\n",
    "                  TimeSeriesOutcome('Infected'),\n",
    "                  TimeSeriesOutcome('Susceptible'),\n",
    "                  TimeSeriesOutcome('Resistant')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the number of replications\n",
    "model.replications = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform EMA experiments\n",
    "\n",
    "In this part we run the EMA experiments using the previously set parameters. We then store the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[MainProcess/INFO] performing 100 scenarios * 1 policies * 1 model(s) = 100 experiments\n",
      "[MainProcess/INFO] performing experiments sequentially\n",
      "[MainProcess/INFO] 10 cases completed\n",
      "[MainProcess/INFO] 20 cases completed\n",
      "[MainProcess/INFO] 30 cases completed\n",
      "[MainProcess/INFO] 40 cases completed\n",
      "[MainProcess/INFO] 50 cases completed\n",
      "[MainProcess/INFO] 60 cases completed\n",
      "[MainProcess/INFO] 70 cases completed\n",
      "[MainProcess/INFO] 80 cases completed\n",
      "[MainProcess/INFO] 90 cases completed\n",
      "[MainProcess/INFO] 100 cases completed\n",
      "[MainProcess/INFO] experiments finished\n"
     ]
    }
   ],
   "source": [
    "# running the EMA experiments with the aforementioned parameters and outputs\n",
    "results = perform_experiments(model, 100)\n",
    "\n",
    "# opening the results\n",
    "experiments, outcomes = results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Save"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process outcomes\n",
    "In this part we reshape the results so that they can be more easily plotted later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes[random.choice(list(outcomes))].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get shape of every outcome (should all be identical?)\n",
    "# for k in list(outcomes):\n",
    "#     print(outcomes[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_2D = {key:np.mean(outcomes[key],axis=1) for key in outcomes.keys()}\n",
    "results_2D = (experiments.copy(), outcomes_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_2D[random.choice(list(outcomes))].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize outcomes\n",
    "In this part, we plot the three different model outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ema_workbench.analysis.plotting import lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting all of the results\n",
    "plt.rcParams['figure.figsize'] = [10, 12]\n",
    "\n",
    "figure = lines(experiments, outcomes_2D) #show lines, and end state density\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sensitivity analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SALib.analyze import sobol\n",
    "from ema_workbench.em_framework.salib_samplers import get_SALib_problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa_results = perform_experiments(model, scenarios=100, uncertainty_sampling='sobol')\n",
    "sa_experiments, sa_outcomes = sa_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Sample size for Sobol\n",
    "To calculate first-order, second-order and total sensitivity indices, \n",
    "this gives a sample size of n(2p+2), where p is the number of input parameters, \n",
    "and n is a baseline sample size which should be large enough to stabilize the estimation of the indices.\n",
    "from https://pynetlogo.readthedocs.io/en/latest/_docs/SALib_ipyparallel.html#Using-SALib-for-sensitivity-analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the first axis of the result array (why?)\n",
    "sa_outcomes_2D = {key:np.mean(sa_outcomes[key],axis=1) for key in sa_outcomes.keys()}\n",
    "sa_results_2D = (sa_experiments.copy(), sa_outcomes_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalising the number of resistant agents\n",
    "normalized_resistant = (sa_outcomes_2D['Resistant'][:,-1] / sa_experiments['num_nodes']).to_numpy()\n",
    "normalized_resistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performing the sobol analysis\n",
    "sa_problem = get_SALib_problem(model.uncertainties)\n",
    "Si = sobol.analyze(sa_problem, normalized_resistant,\n",
    "                   calc_second_order=True, print_to_console=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the results from the analysis\n",
    "scores_filtered = {k:Si[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "Si_df = pd.DataFrame(scores_filtered, index=sa_problem['names'])\n",
    "\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(1)\n",
    "\n",
    "indices = Si_df[['S1','ST']]\n",
    "err = Si_df[['S1_conf','ST_conf']]\n",
    "\n",
    "indices.plot.bar(yerr=err.values.T,ax=ax)\n",
    "fig.set_size_inches(8,6)\n",
    "fig.subplots_adjust(bottom=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Si_filter = {k:Si[k] for k in ['ST','ST_conf','S1','S1_conf']}\n",
    "Si_df = pd.DataFrame(Si_filter, index=sa_problem['names'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from SSF2021.src.plot import plot_sobol_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('whitegrid')\n",
    "fig = plot_sobol_indices(Si, sa_problem, criterion='ST', threshold=0.005)\n",
    "fig.set_size_inches(7,7)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
